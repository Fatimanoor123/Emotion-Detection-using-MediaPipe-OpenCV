# ğŸ­ Emotion Detection using MediaPipe & OpenCV

This project detects **human emotions in real-time** using **MediaPipe FaceMesh** and **OpenCV**.  
It analyzes facial landmarks to classify simple emotions such as **Happy**, **Sad**, **Surprised**, and **Neutral**.

---

## ğŸ§  Project Overview

This project uses:
- **MediaPipe FaceMesh** for facial landmark detection (eyes, lips, etc.)
- **OpenCV** for image/video frame processing
- A custom rule-based classifier to determine emotion from facial features

It runs in **Google Colab** and saves the output video with detected emotions displayed on-screen in bold text.

---

## ğŸš€ Features

âœ… Detects facial emotions in video files  
âœ… Uses real-time FaceMesh landmark extraction  
âœ… Displays the emotion name on screen in **large, dark text**  
âœ… Saves the processed output video to **Google Drive**  
âœ… Beginner-friendly â€” easy to extend with ML-based classifiers

---

## ğŸ“‚ Folder Structure

```
Emotion-Detection-MediaPipe/
â”‚
â”œâ”€â”€ emotion_detection.ipynb     # Main Google Colab notebook
â”œâ”€â”€ input_videos/               # Folder containing input videos
â”œâ”€â”€ output_videos/              # Folder where processed videos are saved
â””â”€â”€ README.md                   # Project documentation
```

---

## ğŸ§© Dependencies

Install the required libraries before running the notebook:
```bash
pip install opencv-python mediapipe numpy scipy
```

---

## ğŸ§¾ How It Works

1. **Load video** from Google Drive  
2. **Detect facial landmarks** using MediaPipe FaceMesh  
3. **Compute geometric ratios** (eyes, mouth, eyebrows)  
4. **Classify emotion** based on feature distances  
5. **Overlay detected emotion** text on the frame  
6. **Save the processed video** with emotion labels

---

## ğŸ’¡ Emotion Logic (Rule-Based)

| Emotion     | Rule                                                                 |
|--------------|----------------------------------------------------------------------|
| **Happy**    | Mouth width â†‘, mouth height â†‘                                       |
| **Sad**      | Mouth narrow â†“, eyes slightly closed â†“                              |
| **Surprised**| Mouth height â†‘â†‘, eyes wide open â†‘â†‘                                  |
| **Neutral**  | No major change in facial geometry                                  |

---

## ğŸ¥ Example Output

When the model processes a video, youâ€™ll see text such as:
```
Emotion: Happy
```
<img width="552" height="887" alt="image" src="https://github.com/user-attachments/assets/6eff93fb-b132-4362-bb37-379d35506b2a" />

displayed clearly on the personâ€™s face in large, dark text.

---

## ğŸ“ Example Paths

Make sure to update the paths in your notebook before running:

```python
video_path = "/content/drive/MyDrive/AI ML Projects/Emotion-Detection/input/video1.mp4"
output_path = "/content/drive/MyDrive/AI ML Projects/Emotion-Detection/output/video1_output.mp4"
```

---

## ğŸ§ª Future Work

- Add a CNN-based deep learning emotion classifier  
- Real-time webcam emotion recognition  
- Integration with sentiment-based alert systems  
- Emotion analytics dashboard for study or HR tools  

---

## ğŸ§‘â€ğŸ’» Author

**Fatima Noor**  
AI/ML Developer | Python Enthusiast  
ğŸ“§ [GitHub Profile Link Here]  
ğŸ“ Based in Pakistan  

---

## ğŸª„ Inspiration

The project was inspired by how subtle changes in facial expressions reveal human emotions â€” bringing AI closer to understanding empathy.  
Built with â¤ï¸ using **MediaPipe**, **OpenCV**, and **Python**.
